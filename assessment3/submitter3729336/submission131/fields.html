<!DOCTYPE html>
<html lang="en">
  <head>
    <meta charset="utf-8">
    <title>Submission 131 from Anon (coursera_user_id: 3729336, session_user_id: 96c027538a5d7e3d38f9b04f5434b20bc756952d)</title>
    <link href="../../../export.css" rel="stylesheet">
  </head>
  <body>
    <h1>Submission 131 from Anon (coursera_user_id: 3729336, session_user_id: 96c027538a5d7e3d38f9b04f5434b20bc756952d)</h1>
    <div class="field-name" id="81e36f2dbf4473c3">Paste in your short (600-word) essay or link to your short film or video (2-3 minute) on your reflections from the Risk Horizon game.<br><br></div>
    <div class="field-value">1. The whole game focus on risk management. To succeed and pass levels it is necessary to trade off different aspects such as criticality of the comets (severity and probability), time spent on protection research or insurance investment among others. In my case, I prioritized the development of buildings to enable a faster knowledge development but in parallel I spent money in insurance (33% or 50% depending on the level) as well as in protection. Due to comets will impact sooner or later it is very important to invest in insurance and protection to minimize damages and economic losses and in consequence to sustain the knowledge level. If these parameters are not managed the impact of the comets will have such impact in the knowledge that the target will not be reached by the end of the time given for a level.<br /><br />2. When I have repeated the game, I have tried to learn about the comets behavior in each level and anticipate the probability and severity of the impacts. With this approach, I have fine tuned the balance reached in terms of insurance and protection in previous levels. <br /><br />3. In some cases risk management takes into consideration the detectability of issues as an important element in terms of criticality. The rational behind the concept of detectability consists on the assumption that a non detectable issue is riskier and implies a higher probability that a critical issue occurs. FMEA was developed in the late 40's of the 20th century by the US Armed Forced and was used by NASA in programs like the Apollo (<a href="http://www.hq.nasa.gov/office/codeq/software/ComplexElectronics/techniques/fmea.htm" title="Link: http://www.hq.nasa.gov/office/codeq/software/ComplexElectronics/techniques/fmea.htm">http://www.hq.nasa.gov/office/codeq/software/ComplexElectronics/techniques/fmea.htm</a>). In our communities, non detectable issues also implies a higher risk for systemic issues (eg. economic bubbles) and could be introduced in the game as health issues in the population that reduce the knowledge development speed but are not identified by government until they are largely spread.<br /></div>
  </body>
</html>